# Unit tests for nodes

## Folder structure

The test should be created in a sub-folder of the node called tests.

Please organise the file using these sub-folders:

- data: place here any data file that is needed to create test cases, while it is possible to mock the data. Feel free to add a text file explaing how the data was produced. Mocking data is also possible but it may be not practical for complex datasets.
- results: create this folder to store your results, i.e. files that would be created by your analysis such as the plots. It should be empty, do not commit your results. To assure this is the case, add a file name .gitinore in the folder with this code:

```gitignore
# Ignore everything in this directory
*

# But do not ignore this file
!.gitignore     
```

## General guideline and information

A good starting point, especially starting from scratch, it is to test for the class type, then that the inputs have the right formats and then move to some simple operation or trivial case.
Build more complex cases from the simpler ones and exploits your tests to refector the code as needed. 
Try to test as many reasonable cases as possible, both successfull and not. 
Remeber to test for exceptions. 
We also suggest to develop using test drive development tecniques that will ensure a high test coverage and a good code structure. Yes, do not forget to keep refactoring to improve the code.

You can find some samples below taken from the cz_parametrisation node, where all objects are tested

Currently there is no way to differentiate from tests that require a QPU (i.e. measurments) and those that do not (i.e. analyses).
Since the latter are simpler to write, start with those that, in general, are more likely to benefit from unit tests as there is much more logic in the analysis than in the measurment.

If you need to test some complex scenario, such as those involving sweep, it is probably easier to start writing code and tests from the lowest level and then compose those objects to hendle the more complex scenario considered. 

## Example Tests

### Test class type
```python
def test_canCreateCorrectType():
    c = CZ_Parametrization_Fix_Duration_Node("cz_char_fixCurrent", couplers = ["q14_q15"])
    assert isinstance(c, CZ_Parametrization_Fix_Duration_Node)
    assert isinstance(c, ScheduleNode)
```
The suggested very first test is to istantiate the class and make sure it has the correct type(s) following any inheritance.

### Test input parameters
```python
def test_CanGetQubitsFromCouplers():
    c = CZ_Parametrization_Fix_Duration_Node("cz_char_fixCurrent", couplers = ["q14_q15"])
    assert c.all_qubits == ["q14", "q15"]
    assert c.couplers == ['q14_q15']
```
Make sure all inputs and their manipulations are correctly initialised in the constructor, in this case the qubits are taken from the coupler pair

### Test exception
```python
def test_ValidationReturnErrorWithSameQubitCoupler():
    with pytest.raises(ValueError):
       CZ_Parametrization_Fix_Duration_Node("cz_char_fixCurrent", couplers = ["q14_q14"])
```
Inputs can be incorrect and should always be tested to avoid unexpected behaviour down the line which can be difficult to trace back to the origin. There are infinite number of possible errors, so it is impossible to cover them all, but at least the obvious ones should be considered. In this case a typical typing error with the couple have the same qubit twice.

### Test with data
```python
@pytest.fixture(autouse=True)
def setup_good_data():
    os.environ["DATA_DIR"] = str(Path(__file__).parent / "results")
    dataset_path = Path(__file__).parent / "data" / "dataset_good_quality_freq_amp.hdf5"
    print(dataset_path)
    ds = xr.open_dataset(dataset_path)
    ds = ds.isel(ReIm=0) + 1j * ds.isel(ReIm=1)
    d14 = ds.yq14.to_dataset()
    d15 = ds.yq15.to_dataset()
    d14.yq14.attrs["qubit"] = "q14"
    d15.yq15.attrs["qubit"] = "q15"
    freqs = ds[f"cz_pulse_frequenciesq14_q15"].values  # MHz
    amps = ds[f"cz_pulse_amplitudesq14_q15"].values  # uA
    return d14, d15, freqs, amps
```
This is an example of how to load data for testing the analysis of a node, please note that the specifics may change as we are about to change the dataset format at the time of writing this; however, the principle will be the same.

This data can then be used in multiple tests, for example:
```python
def test_canGetMaxFromQ1(setup_good_data):
    d14, d15, freqs, amps = setup_good_data
    c = CZ_Parametrisation_Frequency_vs_Amplitude_Q1_Analysis(d14, freqs, amps)
    result = c.run_fitting()
    indexBestFreq = np.where(freqs == result[0])[0]
    indexBestAmp = np.where(amps == result[1])[0]
    assert indexBestFreq[0] == 9
    assert indexBestAmp[0] == 13


def test_canGetMinFromQ2(setup_good_data):
    d14, d15, freqs, amps = setup_good_data
    c = CZ_Parametrisation_Frequency_vs_Amplitude_Q2_Analysis(d15, freqs, amps)
    result = c.run_fitting()
    indexBestFreq = np.where(freqs == result[0])[0]
    indexBestAmp = np.where(amps == result[1])[0]
    assert indexBestFreq[0] == 10
    assert indexBestAmp[0] == 12
```
These two tests make sure that the return values are correct for the two qubits that are connected by the coupler.

### Test creationg of images from plotter
```python
def test_canPlotBad(setup_bad_data):
    matplotlib.use("Agg")
    d14, d15, freqs, amps = setup_bad_data
    c14 = CZ_Parametrisation_Frequency_vs_Amplitude_Q1_Analysis(d14, freqs, amps)
    result = c14.run_fitting()

    figure_path = os.environ["DATA_DIR"] + "/Frequency_Amplitude_bad_q14.png"
    # Remove the file if it already exists
    if os.path.exists(figure_path):
        os.remove(figure_path)

    fig, ax = plt.subplots(figsize=(15, 7), num=1)
    plt.Axes
    c14.plotter(ax)
    fig.savefig(figure_path)
    plt.close()

    assert os.path.exists(figure_path)
    from PIL import Image

    with Image.open(figure_path) as img:
        assert img.format == "PNG", "File should be a PNG image"

    c15 = CZ_Parametrisation_Frequency_vs_Amplitude_Q2_Analysis(d15, freqs, amps)
    result = c15.run_fitting()

    figure_path = os.environ["DATA_DIR"] + "/Frequency_Amplitude_bad_q15.png"
    # Remove the file if it already exists
    if os.path.exists(figure_path):
        os.remove(figure_path)

    fig, ax = plt.subplots(figsize=(15, 7), num=1)
    plt.Axes
    c15.plotter(ax)
    fig.savefig(figure_path)
    plt.close()

    assert os.path.exists(figure_path)
    from PIL import Image

    with Image.open(figure_path) as img:
        assert img.format == "PNG", "File should be a PNG image"
```
This is an example on how to save files in the "results" sub-folder within the "tests" folder. The code make sure the expected file exists and has the correct format. The created files can be inspected by the developer. A possible extension would be to upload the images in the data folder and check the those produced by the test are identical.

### Complex dataset for comparing results
```python
@pytest.fixture(autouse=True)
def setup_bad_data():
    dataset_path = Path(__file__).parent / "data" / "dataset_bad_quality_freq_amp.hdf5"
    print(dataset_path)
    ds = xr.open_dataset(dataset_path)
    ds = ds.isel(ReIm=0) + 1j * ds.isel(ReIm=1)
    d14 = ds.yq14.to_dataset()
    d15 = ds.yq15.to_dataset()
    d14.yq14.attrs["qubit"] = "q14"
    d15.yq15.attrs["qubit"] = "q15"
    freqs = ds[f"cz_pulse_frequenciesq14_q15"].values  # MHz
    amps = ds[f"cz_pulse_amplitudesq14_q15"].values  # uA
    q14Ana = CZ_Parametrisation_Frequency_vs_Amplitude_Q1_Analysis(d14, freqs, amps)
    q14Res = q14Ana.run_fitting()
    q15Ana = CZ_Parametrisation_Frequency_vs_Amplitude_Q2_Analysis(d15, freqs, amps)
    q15Res = q15Ana.run_fitting()
    return q14Res, q15Res


def test_combineBadResultsReturnNoValidPoint(setup_bad_data):
    q14Res, q15Res = setup_bad_data
    c = CZ_Parametrisation_Combined_Frequency_vs_Amplitude_Analysis(q14Res, q15Res)
    r = c.are_frequencies_compatible()
    assert r == False
    r = c.are_amplitudes_compatible()
    assert r == False
    r = c.are_two_qubits_compatible()
    assert r == False
```
In this example, the data produced is loaded from a file that has data that is not a good working point. Note that there two analyses are run in the setup; the combination is run in the test, so that, if needed in other tests, the data could be modified for specific cases.
This is a failure test, making sure that bad inputs are not recognised as good working points.

### Even more complex setup
```python
def setup_data():
    # It should be a single dataset, but we do not have one yet, so we loop over existing files
    dataset_path = Path(__file__).parent / "data" / "dataset_good_quality_freq_amp.hdf5"
    print(dataset_path)
    ds = xr.open_dataset(dataset_path)
    ds = ds.isel(ReIm=0) + 1j * ds.isel(ReIm=1)
    d14 = ds.yq14.to_dataset()
    d15 = ds.yq15.to_dataset()
    d14.yq14.attrs["qubit"] = "q14"
    d15.yq15.attrs["qubit"] = "q15"
    freqs = ds[f"cz_pulse_frequenciesq14_q15"].values  # MHz
    amps = ds[f"cz_pulse_amplitudesq14_q15"].values  # uA
    q14Ana = CZ_Parametrisation_Frequency_vs_Amplitude_Q1_Analysis(d14, freqs, amps)
    q14Res = q14Ana.run_fitting()
    q15Ana = CZ_Parametrisation_Frequency_vs_Amplitude_Q2_Analysis(d15, freqs, amps)
    q15Res = q15Ana.run_fitting()
    c1 = CZ_Parametrisation_Combined_Frequency_vs_Amplitude_Analysis(q14Res, q15Res)

    dataset_path = Path(__file__).parent / "data" / "dataset_bad_quality_freq_amp.hdf5"
    print(dataset_path)
    ds = xr.open_dataset(dataset_path)
    ds = ds.isel(ReIm=0) + 1j * ds.isel(ReIm=1)
    d14 = ds.yq14.to_dataset()
    d15 = ds.yq15.to_dataset()
    d14.yq14.attrs["qubit"] = "q14"
    d15.yq15.attrs["qubit"] = "q15"
    freqs_bad = ds[f"cz_pulse_frequenciesq14_q15"].values  # MHz
    amps_bad = ds[f"cz_pulse_amplitudesq14_q15"].values  # uA
    q14Ana = CZ_Parametrisation_Frequency_vs_Amplitude_Q1_Analysis(
        d14, freqs_bad, amps_bad
    )
    q14Res = q14Ana.run_fitting()
    q15Ana = CZ_Parametrisation_Frequency_vs_Amplitude_Q2_Analysis(
        d15, freqs_bad, amps_bad
    )
    q15Res = q15Ana.run_fitting()
    c2 = CZ_Parametrisation_Combined_Frequency_vs_Amplitude_Analysis(q14Res, q15Res)

    dataset_path = (
        Path(__file__).parent / "data" / "dataset_good_quality_freq_amp_2.hdf5"
    )
    print(dataset_path)
    ds = xr.open_dataset(dataset_path)
    ds = ds.isel(ReIm=0) + 1j * ds.isel(ReIm=1)
    d14 = ds.yq14.to_dataset()
    d15 = ds.yq15.to_dataset()
    d14.yq14.attrs["qubit"] = "q14"
    d15.yq15.attrs["qubit"] = "q15"
    freqs_2 = ds[f"cz_pulse_frequenciesq14_q15"].values  # MHz
    amps_2 = ds[f"cz_pulse_amplitudesq14_q15"].values  # uA
    q14Ana = CZ_Parametrisation_Frequency_vs_Amplitude_Q1_Analysis(d14, freqs_2, amps_2)
    q14Res = q14Ana.run_fitting()
    q15Ana = CZ_Parametrisation_Frequency_vs_Amplitude_Q2_Analysis(d15, freqs_2, amps_2)
    q15Res = q15Ana.run_fitting()
    c3 = CZ_Parametrisation_Combined_Frequency_vs_Amplitude_Analysis(q14Res, q15Res)

    list_of_results = [(c1, 0.1), (c2, 0.2), (c3, 0.3)]
    return list_of_results, freqs, amps, freqs_2, amps_2
```

In this case, three points are loaded and the analysis is run on each of them. The results are returned for each point and can be used in different tests, for example by removing elements in the list_results array. 

# Unit tests for infrastructure

Coming soon